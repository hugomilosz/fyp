{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhugomilosz\u001b[0m (\u001b[33mhugomilosz-imperial-college-london\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/vol/bitbucket/hrm20/fyp/wandb/run-20250422_172743-uhuwl6oc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/hugomilosz-imperial-college-london/bert-tiny_multi_nli_analysis/runs/uhuwl6oc' target=\"_blank\">good-galaxy-21</a></strong> to <a href='https://wandb.ai/hugomilosz-imperial-college-london/bert-tiny_multi_nli_analysis' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/hugomilosz-imperial-college-london/bert-tiny_multi_nli_analysis' target=\"_blank\">https://wandb.ai/hugomilosz-imperial-college-london/bert-tiny_multi_nli_analysis</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/hugomilosz-imperial-college-london/bert-tiny_multi_nli_analysis/runs/uhuwl6oc' target=\"_blank\">https://wandb.ai/hugomilosz-imperial-college-london/bert-tiny_multi_nli_analysis/runs/uhuwl6oc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact eval_dict_run0:v0, 99.62MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:0.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact eval_dict_run1:v0, 99.62MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:0.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact eval_dict_run2:v0, 99.62MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact eval_dict_run3:v0, 99.62MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact eval_dict_run4:v0, 99.62MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact eval_dict_run5:v0, 99.62MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:0.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact eval_dict_run6:v0, 99.62MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact eval_dict_run7:v0, 99.62MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:4.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact eval_dict_run8:v0, 99.62MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:0.6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact eval_dict_run9:v0, 99.62MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:0.4\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "def compute_majority_votes(model: str, dataset: str, num_runs: int = 10, project_path_base: str = \"hugomilosz-imperial-college-london\") -> dict:\n",
    "    \"\"\"\n",
    "    Compute majority vote binary predictions from multiple wandb runs.\n",
    "\n",
    "    Parameters:\n",
    "    - model (str): Model name from AVAILABLE_MODELS\n",
    "    - dataset (str): Dataset name from AVAILABLE_DATASETS\n",
    "    - num_runs (int): Number of runs to aggregate over\n",
    "    - project_path_base (str): Base path for wandb project\n",
    "\n",
    "    Returns:\n",
    "    - dict: {method_name: majority_vote_array}\n",
    "    \"\"\"\n",
    "    project_name = f\"{model}_{dataset}_analysis\"\n",
    "    run_names = [f\"{model}_{dataset}_run{i}\" for i in range(num_runs)]\n",
    "    project_path = f\"{project_path_base}/{project_name}\"\n",
    "\n",
    "    method_binaries = defaultdict(list)\n",
    "\n",
    "    api_run = wandb.init(project=project_name, job_type=\"aggregate_eval_summary\")\n",
    "\n",
    "    for run_name in run_names:\n",
    "        run_id = run_name.split(\"_\")[-1]\n",
    "        artifact_path = f\"{project_path}/eval_summary_{run_id}:v0\"\n",
    "        artifact = api_run.use_artifact(artifact_path, type='pickle')\n",
    "        artifact_dir = artifact.download()\n",
    "        \n",
    "        with open(os.path.join(artifact_dir, f\"eval_summary_{run_id}.pkl\"), \"rb\") as f:\n",
    "            eval_summary = pickle.load(f)\n",
    "\n",
    "        binary_scores = eval_summary[\"binary_scores\"]\n",
    "\n",
    "        for method_name, epoch_values in binary_scores.items():\n",
    "            if not epoch_values:\n",
    "                continue\n",
    "            last_epoch_array = epoch_values[-1]\n",
    "            method_binaries[method_name].append(np.array(last_epoch_array))\n",
    "\n",
    "    majority_vote_dict = {}\n",
    "\n",
    "    for method, binary_arrays in method_binaries.items():\n",
    "        stacked = np.stack(binary_arrays)\n",
    "        majority = (np.sum(stacked, axis=0) >= (len(binary_arrays) / 2)).astype(int)\n",
    "        majority_vote_dict[method] = majority\n",
    "\n",
    "    api_run.finish()\n",
    "    return majority_vote_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "votes = compute_majority_votes(model=\"bert-tiny\", dataset=\"multi_nli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          aum        datamap          el2n     grand  \\\n",
      "aum                  1.000000       0.615773      0.216838       1.0   \n",
      "datamap              0.619622       1.000000      0.009117       1.0   \n",
      "el2n                 0.912893       0.038143      1.000000       1.0   \n",
      "grand                0.708293       0.703893      0.168240       1.0   \n",
      "loss                 0.926675       0.027609      0.940217       1.0   \n",
      "forgetting      278148.000000  276420.000000  66068.000000  392702.0   \n",
      "regularisation       0.851895       0.542786      0.263827       1.0   \n",
      "\n",
      "                        loss  forgetting  regularisation  \n",
      "aum                 0.221911         1.0        0.762601  \n",
      "datamap             0.006653         1.0        0.488930  \n",
      "el2n                0.947902         1.0        0.994294  \n",
      "grand               0.169615         1.0        0.634051  \n",
      "loss                1.000000         1.0        0.993124  \n",
      "forgetting      66608.000000         1.0   248993.000000  \n",
      "regularisation      0.265670         1.0        1.000000  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "methods = list(votes.keys())\n",
    "overlap_matrix = np.zeros((len(methods), len(methods)))\n",
    "\n",
    "for i, method_i in enumerate(methods):\n",
    "    for j, method_j in enumerate(methods):\n",
    "        easy_i = votes[method_i] == 1\n",
    "        easy_j = votes[method_j] == 1\n",
    "        overlap = np.sum(np.logical_and(easy_i, easy_j))\n",
    "        total_easy = np.sum(easy_i)\n",
    "        overlap_matrix[i, j] = overlap / total_easy if total_easy > 0 else 0.0\n",
    "\n",
    "# To get it nicely formatted\n",
    "overlap_df = pd.DataFrame(overlap_matrix, index=methods, columns=methods)\n",
    "print(overlap_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fypenv",
   "language": "python",
   "name": "fypenv"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
